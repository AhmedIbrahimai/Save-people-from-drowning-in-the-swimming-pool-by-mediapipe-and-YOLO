{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e654192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\amb/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-2-18 Python-3.9.13 torch-1.12.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "#model = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt', force_reload=True)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "cap=cv2.VideoCapture('vid.mp4')\n",
    "\n",
    "\n",
    "#def POINTS(event, x, y, flags, param):\n",
    "    #if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        #colorsBGR = [x, y]\n",
    "        #print(colorsBGR)\n",
    "        \n",
    "\n",
    "#cv2.namedWindow('FRAME')\n",
    "#cv2.setMouseCallback('FRAME', POINTS)\n",
    "\n",
    "tracker = Tracker()\n",
    "#area = [(377,315),(429,373),(535,339),(500,296)]\n",
    "c = set()\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if ret==False:\n",
    "        break\n",
    "    frame=cv2.resize(frame,(1020,500))\n",
    "    #cv2.polylines(frame,[np.array(area,np.int32)],True,(0,255,0),2)\n",
    "    results = model(frame)\n",
    "    #frame = np.squeeze(results.render())\n",
    "    points = []\n",
    "    for index , row in results.pandas().xyxy[0].iterrows():\n",
    "        x1 = int(row['xmin'])\n",
    "        y1 = int(row['ymin'])\n",
    "        x2 = int(row['xmax'])\n",
    "        y2 = int(row['ymax'])\n",
    "        n=(row['name'])\n",
    "        \n",
    "        if 'person' in n:\n",
    "            points.append([x1,y1,x2,y2]) \n",
    "            #cv2.rectangle(frame,(x1,y1),(x2,y2),(255,0,255),2)\n",
    "            #cv2.putText(frame,str(n),(x1,y1),cv2.FONT_HERSHEY_PLAIN,2,(255,0,255),2)\n",
    "    boxes_id = tracker.update(points) \n",
    "    #print(boxes_id)\n",
    "    #print(len(points))\n",
    "    num = len(points)\n",
    "    #ids = []\n",
    "    id = []\n",
    "    xx =[]\n",
    "    yy = []\n",
    "    person_id = []\n",
    "    n = []\n",
    "    for box_id in boxes_id:\n",
    "        x , y , w , h , idd = box_id\n",
    "        xx.append(x)\n",
    "        yy.append(y)\n",
    "        id.append(idd)\n",
    "        #person_id = []\n",
    "        #ids = len(person_id)\n",
    "        #print(ids)\n",
    "        #print('xx',xx,':','x',x)\n",
    "        try:\n",
    "            if xx[-1] != xx[-2] and yy[-1] != yy[-2]:\n",
    "               # print('yeeeeeeeeeeeeeeeeeeees',xx)\n",
    "                All= list(zip(id,xx))\n",
    "                per_id , x_coor =zip(*All)       \n",
    "                print(per_id[-1],':',x_coor[-1])\n",
    "                person_id.append([per_id])\n",
    "                #ids = person_id[-1]\n",
    "                #print(ids)\n",
    "                #for t in per_id:\n",
    "\n",
    "                #cv2.putText(frame,'id number '+str(t) ,(20,90),cv2.FONT_HERSHEY_PLAIN,2,(0,255,255),3)\n",
    "                #cv2.putText(frame,'id number '+str(id) +' is moving',(20,110),cv2.FONT_HERSHEY_PLAIN,2,(0,255,255),3)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                \n",
    "                if xx[-1] == xx[-2] or yy[-1] == yy[-2]:\n",
    "                    All= list(zip(id,xx))\n",
    "                    per_idd , x_coor =zip(*All)\n",
    "                    #person_id.append([per_idd])\n",
    "                    n.append([per_idd])\n",
    "                \n",
    "                    #cv2.putText(frame,'id number '+str(idd) +'is not moving',(20,150),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),3)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "        print(n)\n",
    "        cv2.rectangle(frame,(x,y),(w,h),(0,255,0),2)\n",
    "        cv2.putText(frame,'number of persons is='+str(num),(20,50),cv2.FONT_HERSHEY_PLAIN,2,(0,255,255),3)\n",
    "        cv2.putText(frame,'person ID is='+str(id[-1]),(x,y),cv2.FONT_HERSHEY_PLAIN,1,(255,0,255),2)\n",
    "        #results = cv2.pointPolygonTest(np.array(area,np.int32),(w,h),False)\n",
    "        #print(results)\n",
    "        #if results>= 0 :\n",
    "            #c.add(idd)\n",
    "        #try:    \n",
    "            #for idx , hh in enumerate(person_id):\n",
    "                #print(hh.index(0))\n",
    "        #except:\n",
    "            #pass\n",
    "    #for idx , ff in enumerate(person_id):\n",
    "        #print(ff)\n",
    "        #for mm in ff:\n",
    "            #print(mm)\n",
    "           # for id in mm:\n",
    "                #print(id)\n",
    "               # if id ==0:\n",
    "                    #print('yeeeeeeeeeeeeees')\n",
    "                   # cv2.putText(frame,'id number '+str(id) + ' is moving' ,(20,90),cv2.FONT_HERSHEY_PLAIN,2,(0,255,255),3)\n",
    "               # elif id==1:\n",
    "                   # cv2.putText(frame,'id number '+str(id) + ' is moving' ,(20,117),cv2.FONT_HERSHEY_PLAIN,2,(0,255,255),3)\n",
    "                #elif id==2:\n",
    "                  #  cv2.putText(frame,'id number '+str(id) + ' is moving' ,(20,142),cv2.FONT_HERSHEY_PLAIN,2,(0,255,255),3)    \n",
    "                    \n",
    "    try:\n",
    "        cv2.putText(frame,'id number '+str(person_id[-1]) + ' moving' ,(20,90),cv2.FONT_HERSHEY_PLAIN,2,(0,255,255),3)\n",
    "        cv2.putText(frame,'id number '+str(n) +'is not moving',(20,150),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),3)\n",
    "    except:\n",
    "        pass\n",
    "    #print(c) \n",
    "    #a = len(c)\n",
    "    #cv2.putText(frame,'number of people is ='+str(a),(50,65),cv2.FONT_HERSHEY_PLAIN,3,(0,0,255),2)\n",
    "    \n",
    "    cv2.imshow('FRAME',frame)\n",
    "    if cv2.waitKey(1)&0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f62f017c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\amb\\\\Downloads\\\\swim detection'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9fad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b21f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e79aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57cb4d2c",
   "metadata": {},
   "source": [
    "### Swim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0a0c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\amb/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-2-19 Python-3.9.13 torch-1.12.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from tracker import *\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import playsound\n",
    "from mutagen.mp3 import MP3\n",
    "import time\n",
    "import miniaudio\n",
    "\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "ALARM_PATH = \"accident.mp3\"\n",
    "#model = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt', force_reload=True)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "cap=cv2.VideoCapture('vid.mp4')\n",
    "\n",
    "\n",
    "tracker = Tracker()\n",
    "c = set()\n",
    "\n",
    "\n",
    "def calc_angle(a,b,c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    radians = np.arctan2(c[1]-b[1],c[0]-b[0]) - np.arctan2(a[1]-b[1],a[0]-b[0])\n",
    "    angle = np.abs(radians*180/np.pi)\n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "    return angle\n",
    "\n",
    "file='assets_alarm.mp3'\n",
    "audio = MP3(file)\n",
    "length=audio.info.length\n",
    "\n",
    "frame_check = 7\n",
    "flag = 0\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if ret==False:\n",
    "        break\n",
    "    #frame=cv2.resize(frame,(1020,500))\n",
    "    results = model(frame)\n",
    "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Apply the mediapipe pose detection module for detection\n",
    "    result = pose.process(imgRGB)\n",
    "    #print(results.pose_landmarks)\n",
    "    h , w , c = frame.shape\n",
    "    # Draw landmarks\n",
    "    if result.pose_landmarks:\n",
    "        mpDraw.draw_landmarks(frame,result.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "        landmarks = result.pose_landmarks.landmark\n",
    "        \n",
    "        #for land in mpPose.PoseLandmark:\n",
    "            #print(land)\n",
    "        l_shoulder = [landmarks[mpPose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "        l_elbow = [landmarks[mpPose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "        l_wrist = [landmarks[mpPose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "        \n",
    "        r_shoulder = [landmarks[mpPose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "        r_elbow = [landmarks[mpPose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "        r_wrist = [landmarks[mpPose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                   landmarks[mpPose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "        l_ang = calc_angle(l_shoulder,l_elbow,l_wrist)\n",
    "        r_ang = calc_angle(r_shoulder,r_elbow,r_wrist)\n",
    "        \n",
    "        cv2.putText(frame,str(int(l_ang)),tuple(np.multiply(l_elbow,[640,480]).astype(int)),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),1)\n",
    "        cv2.putText(frame,str(int(r_ang)),tuple(np.multiply(r_elbow,[640,480]).astype(int)),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),1)\n",
    "        \n",
    "        if l_wrist[1]*h < l_elbow[1]*h < l_shoulder[1]*h and l_ang > 150:\n",
    "\n",
    "            flag += 1\n",
    "            if flag >= frame_check:\n",
    "                cv2.putText(frame,'Warnning!!! someone need help',(20,75),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),2)\n",
    "                stream = miniaudio.stream_file(file)\n",
    "                with miniaudio.PlaybackDevice() as device:\n",
    "                    device.start(stream)\n",
    "                    time.sleep(length)\n",
    "            \n",
    "        elif r_wrist[1]*h < r_elbow[1]*h < r_shoulder[1]*h and r_ang > 150:\n",
    "    \n",
    "            flag += 1\n",
    "            if flag >= frame_check:\n",
    "                cv2.putText(frame,'Warnning!!! someone need help',(20,75),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),2)\n",
    "                stream = miniaudio.stream_file(file)\n",
    "                with miniaudio.PlaybackDevice() as device:\n",
    "                    device.start(stream)\n",
    "                    time.sleep(length)\n",
    "        \n",
    "        \n",
    "   \n",
    "    points = []\n",
    "    for index , row in results.pandas().xyxy[0].iterrows():\n",
    "        \n",
    "        x1 = int(row['xmin'])\n",
    "        y1 = int(row['ymin'])\n",
    "        x2 = int(row['xmax'])\n",
    "        y2 = int(row['ymax'])\n",
    "        n=(row['name'])\n",
    "        \n",
    "        if 'person' in n:\n",
    "            if row['confidence'] > 0.25:\n",
    "                points.append([x1,y1,x2,y2]) \n",
    "            #cv2.rectangle(frame,(x1,y1),(x2,y2),(255,0,255),2)\n",
    "            #cv2.putText(frame,str(n),(x1,y1),cv2.FONT_HERSHEY_PLAIN,2,(255,0,255),2)\n",
    "    boxes_id = tracker.update(points) \n",
    "    num = len(points)\n",
    "    id = []\n",
    "    #person_id = []\n",
    "    for box_id in boxes_id:\n",
    "        x , y , w , h , idd = box_id\n",
    "        id.append(idd)    \n",
    "            \n",
    "        cv2.rectangle(frame,(x,y),(w,h),(0,255,0),2)\n",
    "        cv2.putText(frame,'number of persons is='+str(num),(20,50),cv2.FONT_HERSHEY_PLAIN,2,(255,0,255),3)\n",
    "        cv2.putText(frame,'person ID is='+str(id[-1]),(x,y),cv2.FONT_HERSHEY_PLAIN,1,(255,0,255),2)\n",
    " \n",
    "  \n",
    "    cv2.imshow('FRAME',frame)\n",
    "    if cv2.waitKey(1)&0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefaa29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f3045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d992f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
